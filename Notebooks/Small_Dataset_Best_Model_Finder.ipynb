{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LUwfJpeZQxK3"
      },
      "outputs": [],
      "source": [
        "# All imports\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "from fastai.imports import *\n",
        "from fastai.vision.all import *\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.metrics import SparseCategoricalCrossentropy\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.io import loadmat \n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving files from our Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwz2sxeBQ52r",
        "outputId": "763dc2d8-606c-4872-d5d8-ef53d87e319d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping files into colab\n",
        "!unzip '/content/drive/My Drive/NNDL Project Submission/im.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMdG_yPzQ6UE",
        "outputId": "f28b17c5-f0f4-4d91-fc88-733c7141732b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/NNDL Project Submission/im.zip\n",
            "replace __MACOSX/._im? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input for the labels of our images\n",
        "labels = '/content/drive/My Drive/NNDL Project/imagelabels.mat'\n",
        "image_labels = loadmat(labels)\n",
        "image_labels.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTf8t5T1Q7PQ",
        "outputId": "b6350bcf-776f-4f55-db4d-8df226cc3526"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['__header__', '__version__', '__globals__', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding our image_labels into a dataframe to match with our images\n",
        "df = pd.DataFrame()\n",
        "labels = image_labels['labels'].transpose()\n",
        "labels = labels -1\n",
        "df = pd.DataFrame(labels, columns = ['image_label'])"
      ],
      "metadata": {
        "id": "8jQ1NKm0Q86K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding our image paths to our image_labels dataframe\n",
        "image_path = []\n",
        "for i in range (1,len(labels)+1):\n",
        "  if i<10:\n",
        "    x = '0000' + str(i)\n",
        "  elif i<100:\n",
        "    x = '000' + str(i)\n",
        "  elif i<1000:\n",
        "    x = '00' + str(i)\n",
        "  elif i<10000:\n",
        "    x = '0' + str(i)\n",
        "  else:\n",
        "    break\n",
        "  image_path.append('/content/im/image_'+x+'.jpg')\n",
        "\n",
        "df[\"image_path\"] = image_path "
      ],
      "metadata": {
        "id": "cJMTxsQVQ-Gb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how many images we have per class (top few and bottom few to understand the distributioin of samples)\n",
        "df.image_label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3b98oEZQ_6l",
        "outputId": "83b9e13b-9e34-432a-cb08-351340fbdd1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50    258\n",
              "76    251\n",
              "45    196\n",
              "72    194\n",
              "88    184\n",
              "     ... \n",
              "6      40\n",
              "44     40\n",
              "33     40\n",
              "0      40\n",
              "26     40\n",
              "Name: image_label, Length: 102, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test to see whether the path code works to open the 1st image\n",
        "im = Image.open(df['image_path'][0])\n",
        "width, height = im.size\n",
        "print(width,height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXpAdXOtRBdF",
        "outputId": "637beef4-9153-4db1-f9b4-82189205bebb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "591 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final check on our data frame before loading the images and converting them to (size, size, 3) numpy pixels\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gwJ5JlaKRCtZ",
        "outputId": "28286d39-ac1c-49db-c25f-9ac1001d53fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      image_label                   image_path\n",
              "0              76  /content/im/image_00001.jpg\n",
              "1              76  /content/im/image_00002.jpg\n",
              "2              76  /content/im/image_00003.jpg\n",
              "3              76  /content/im/image_00004.jpg\n",
              "4              76  /content/im/image_00005.jpg\n",
              "...           ...                          ...\n",
              "8184           61  /content/im/image_08185.jpg\n",
              "8185           61  /content/im/image_08186.jpg\n",
              "8186           61  /content/im/image_08187.jpg\n",
              "8187           61  /content/im/image_08188.jpg\n",
              "8188           61  /content/im/image_08189.jpg\n",
              "\n",
              "[8189 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-298e06d4-d391-4cd5-9abe-1b66aac332df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_label</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76</td>\n",
              "      <td>/content/im/image_00001.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76</td>\n",
              "      <td>/content/im/image_00002.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>76</td>\n",
              "      <td>/content/im/image_00003.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>/content/im/image_00004.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76</td>\n",
              "      <td>/content/im/image_00005.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8184</th>\n",
              "      <td>61</td>\n",
              "      <td>/content/im/image_08185.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8185</th>\n",
              "      <td>61</td>\n",
              "      <td>/content/im/image_08186.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8186</th>\n",
              "      <td>61</td>\n",
              "      <td>/content/im/image_08187.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8187</th>\n",
              "      <td>61</td>\n",
              "      <td>/content/im/image_08188.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8188</th>\n",
              "      <td>61</td>\n",
              "      <td>/content/im/image_08189.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8189 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-298e06d4-d391-4cd5-9abe-1b66aac332df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-298e06d4-d391-4cd5-9abe-1b66aac332df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-298e06d4-d391-4cd5-9abe-1b66aac332df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images, convert to numpy array of pixel data, split into train test split, convert to a tensor and return. (Based on img_size input)\n",
        "def split_function(train_df,img_size):\n",
        "    data = train_df.copy()\n",
        "    img_size = img_size\n",
        "    train_image = []\n",
        "    for i in tqdm(range(data.shape[0])):\n",
        "      # inputting images with the required input size\n",
        "      img = image.load_img(data['image_path'][i],target_size=(img_size,img_size,3))\n",
        "      img = image.img_to_array(img)\n",
        "      train_image.append(img)\n",
        "    # appending the image arrays to a new numpy array\n",
        "    train_df = np.array(train_image)\n",
        "    image_label = data['image_label'].to_numpy()\n",
        "\n",
        "    # Since we want only a small number  of images while training the train val test split has been set accordingly\n",
        "    # train, val, test split (0.2, 0.4, 0.4)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_df, image_label, random_state=42, test_size=0.75, stratify = image_label)\n",
        "    X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, random_state=42, test_size=0.75, stratify = y_train)\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "    print('Number of training samples ', len(train_ds))\n",
        "    print('Number of validation samples ', len(val_ds))\n",
        "\n",
        "    # Batching and applying prefetching for faster processing\n",
        "    train_ds = train_ds.cache().batch(32).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "    val_ds = val_ds.cache().batch(32).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    print('Number of training samples after batching ', len(train_ds))\n",
        "    print('Number of validation samples after batching ', len(val_ds))\n",
        "    \n",
        "    return(train_ds, val_ds)"
      ],
      "metadata": {
        "id": "d2fUFuIuRDPc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching all pretrained keras models\n",
        "all_models_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}\n",
        "\n",
        "# List of all pretrained Keras Model\n",
        "all_models_dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n9MsY0cRDL3",
        "outputId": "597b4bb7-1f1c-4c31-84b8-dff36ff7def5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DenseNet121': <function keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'DenseNet169': <function keras.applications.densenet.DenseNet169(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'DenseNet201': <function keras.applications.densenet.DenseNet201(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'EfficientNetB0': <function keras.applications.efficientnet.EfficientNetB0(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB1': <function keras.applications.efficientnet.EfficientNetB1(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB2': <function keras.applications.efficientnet.EfficientNetB2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB3': <function keras.applications.efficientnet.EfficientNetB3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB4': <function keras.applications.efficientnet.EfficientNetB4(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB5': <function keras.applications.efficientnet.EfficientNetB5(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB6': <function keras.applications.efficientnet.EfficientNetB6(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetB7': <function keras.applications.efficientnet.EfficientNetB7(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'EfficientNetV2B0': <function keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2B1': <function keras.applications.efficientnet_v2.EfficientNetV2B1(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2B2': <function keras.applications.efficientnet_v2.EfficientNetV2B2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2B3': <function keras.applications.efficientnet_v2.EfficientNetV2B3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2L': <function keras.applications.efficientnet_v2.EfficientNetV2L(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2M': <function keras.applications.efficientnet_v2.EfficientNetV2M(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'EfficientNetV2S': <function keras.applications.efficientnet_v2.EfficientNetV2S(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'InceptionResNetV2': <function keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'InceptionV3': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'MobileNet': <function keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'MobileNetV2': <function keras.applications.mobilenet_v2.MobileNetV2(input_shape=None, alpha=1.0, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n",
              " 'MobileNetV3Large': <function keras.applications.mobilenet_v3.MobileNetV3Large(input_shape=None, alpha=1.0, minimalistic=False, include_top=True, weights='imagenet', input_tensor=None, classes=1000, pooling=None, dropout_rate=0.2, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'MobileNetV3Small': <function keras.applications.mobilenet_v3.MobileNetV3Small(input_shape=None, alpha=1.0, minimalistic=False, include_top=True, weights='imagenet', input_tensor=None, classes=1000, pooling=None, dropout_rate=0.2, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'NASNetLarge': <function keras.applications.nasnet.NASNetLarge(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'NASNetMobile': <function keras.applications.nasnet.NASNetMobile(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX002': <function keras.applications.regnet.RegNetX002(model_name='regnetx002', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX004': <function keras.applications.regnet.RegNetX004(model_name='regnetx004', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX006': <function keras.applications.regnet.RegNetX006(model_name='regnetx006', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX008': <function keras.applications.regnet.RegNetX008(model_name='regnetx008', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX016': <function keras.applications.regnet.RegNetX016(model_name='regnetx016', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX032': <function keras.applications.regnet.RegNetX032(model_name='regnetx032', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX040': <function keras.applications.regnet.RegNetX040(model_name='regnetx040', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX064': <function keras.applications.regnet.RegNetX064(model_name='regnetx064', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX080': <function keras.applications.regnet.RegNetX080(model_name='regnetx080', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX120': <function keras.applications.regnet.RegNetX120(model_name='regnetx120', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX160': <function keras.applications.regnet.RegNetX160(model_name='regnetx160', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetX320': <function keras.applications.regnet.RegNetX320(model_name='regnetx320', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY002': <function keras.applications.regnet.RegNetY002(model_name='regnety002', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY004': <function keras.applications.regnet.RegNetY004(model_name='regnety004', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY006': <function keras.applications.regnet.RegNetY006(model_name='regnety006', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY008': <function keras.applications.regnet.RegNetY008(model_name='regnety008', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY016': <function keras.applications.regnet.RegNetY016(model_name='regnety016', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY032': <function keras.applications.regnet.RegNetY032(model_name='regnety032', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY040': <function keras.applications.regnet.RegNetY040(model_name='regnety040', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY064': <function keras.applications.regnet.RegNetY064(model_name='regnety064', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY080': <function keras.applications.regnet.RegNetY080(model_name='regnety080', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY120': <function keras.applications.regnet.RegNetY120(model_name='regnety120', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY160': <function keras.applications.regnet.RegNetY160(model_name='regnety160', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'RegNetY320': <function keras.applications.regnet.RegNetY320(model_name='regnety320', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'ResNet101': <function keras.applications.resnet.ResNet101(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n",
              " 'ResNet101V2': <function keras.applications.resnet_v2.ResNet101V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'ResNet152': <function keras.applications.resnet.ResNet152(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n",
              " 'ResNet152V2': <function keras.applications.resnet_v2.ResNet152V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'ResNet50': <function keras.applications.resnet.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n",
              " 'ResNet50V2': <function keras.applications.resnet_v2.ResNet50V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'ResNetRS101': <function keras.applications.resnet_rs.ResNetRS101(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS152': <function keras.applications.resnet_rs.ResNetRS152(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS200': <function keras.applications.resnet_rs.ResNetRS200(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS270': <function keras.applications.resnet_rs.ResNetRS270(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS350': <function keras.applications.resnet_rs.ResNetRS350(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS420': <function keras.applications.resnet_rs.ResNetRS420(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'ResNetRS50': <function keras.applications.resnet_rs.ResNetRS50(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n",
              " 'VGG16': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'VGG19': <function keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
              " 'Xception': <function keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all pretrained Keras models specifically for image classification\n",
        "image_pretrained_models = [\n",
        "        'VGG16',\n",
        "        'VGG19',\n",
        "        'ResNet50',\n",
        "        'ResNet50V2',\n",
        "        'ResNet101',\n",
        "        'ResNet101V2',\n",
        "        'ResNet152',\n",
        "        'ResNet152V2',\n",
        "        'MobileNet',\n",
        "        'MobileNetV2',\n",
        "        'DenseNet121',\n",
        "        'DenseNet169',\n",
        "        'DenseNet201',\n",
        "        'NASNetMobile',\n",
        "        'EfficientNetB0',\n",
        "        'EfficientNetB1',\n",
        "        'EfficientNetB2',\n",
        "        'EfficientNetB3',\n",
        "        'EfficientNetB4',\n",
        "        'EfficientNetB5',\n",
        "        'EfficientNetB6',\n",
        "        'EfficientNetB7',\n",
        "        'EfficientNetV2B0',\n",
        "        'EfficientNetV2B1',\n",
        "        'EfficientNetV2B2',\n",
        "        'EfficientNetV2B3',\n",
        "        'EfficientNetV2S',\n",
        "        'EfficientNetV2M',\n",
        "        'EfficientNetV2L',\n",
        "        'Xception',\n",
        "        'InceptionV3',\n",
        "        'InceptionResNetV2',\n",
        "        'NASNetLarge'\n",
        "    ]"
      ],
      "metadata": {
        "id": "yJnjTmlFRDJN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_func = { 'VGG16' : tf.keras.applications.vgg16.preprocess_input,\n",
        "                    'VGG19':tf.keras.applications.vgg19.preprocess_input,\n",
        "                    'ResNet50':tf.keras.applications.resnet.preprocess_input,\n",
        "                    'ResNet50V2':tf.keras.applications.resnet_v2.preprocess_input,\n",
        "                    'ResNet101':tf.keras.applications.resnet.preprocess_input,\n",
        "                    'ResNet101V2':tf.keras.applications.resnet_v2.preprocess_input,\n",
        "                    'ResNet152':tf.keras.applications.resnet.preprocess_input,\n",
        "                    'ResNet152V2':tf.keras.applications.resnet_v2.preprocess_input,\n",
        "                    'MobileNet':tf.keras.applications.mobilenet.preprocess_input,\n",
        "                    'MobileNetV2':tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "                    'DenseNet121':tf.keras.applications.densenet.preprocess_input,\n",
        "                    'DenseNet169':tf.keras.applications.densenet.preprocess_input,\n",
        "                    'DenseNet201':tf.keras.applications.densenet.preprocess_input,\n",
        "                    'NASNetMobile':tf.keras.applications.nasnet.preprocess_input,\n",
        "                    'EfficientNetB0':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB1':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB2':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB3':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB4':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB5':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB6':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetB7':tf.keras.applications.efficientnet.preprocess_input,\n",
        "                    'EfficientNetV2B0':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2B1':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2B2':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2B3':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2S':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2M':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'EfficientNetV2L':tf.keras.applications.efficientnet_v2.preprocess_input,\n",
        "                    'Xception': tf.keras.applications.xception.preprocess_input,\n",
        "                    'InceptionV3':tf.keras.applications.inception_v3.preprocess_input,\n",
        "                    'InceptionResNetV2':tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
        "                    'NASNetLarge':tf.keras.applications.nasnet.preprocess_input\n",
        "                  }"
      ],
      "metadata": {
        "id": "fNTXo-bjRJnU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching only the models specifically mentioned for image classification\n",
        "image_models = {image_pretrained_model: all_models_dictionary[image_pretrained_model] for image_pretrained_model in image_pretrained_models}\n",
        "\n",
        "# Corresponds to Keras documentation for image specific pretrained models\n",
        "len(image_models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-HIXWcrRJlG",
        "outputId": "d4a37c63-2d55-496f-ed4c-7d05421aa7f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping implementation to reduce over\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Initialising our augmentation layer\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "DwKhqNhPRJig"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_224, val_ds_224 = split_function(df,224)\n",
        "#train_ds_299, val_ds_299 = split_function(df,299)\n",
        "#train_ds_331, val_ds_331 = split_function(df,331)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Q25ursRJfU",
        "outputId": "24e89ac2-6f3a-4413-8fa4-ba2ff68cfacc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8189/8189 [00:46<00:00, 177.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples  1536\n",
            "Number of validation samples  511\n",
            "Number of training samples after batching  48\n",
            "Number of validation samples after batching  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looping over all available image models in Keras\n",
        "model_benchmarks = {'pretrained_model_name' : [], 'num_params' : [], 'validation_accuracy' : [] }\n",
        "\n",
        "train_ds, val_ds = train_ds_224, val_ds_224\n",
        "cnt = 0\n",
        "\n",
        "for pretrained_model_name, model in tqdm(image_models.items()):\n",
        "    if cnt==1:\n",
        "      break\n",
        "    # Special handling for different pretrained models since they require different image input sizes\n",
        "    if pretrained_model_name in ['Xception','InceptionV3','InceptionResNetV2'] :\n",
        "        input_shape=(299, 299, 3)\n",
        "        train_ds, val_ds = train_ds_299, val_ds_299\n",
        "\n",
        "    elif pretrained_model_name == 'NASNetLarge':\n",
        "        input_shape=(331, 331, 3)\n",
        "        train_ds, val_ds = train_ds_331, val_ds_331\n",
        "\n",
        "    else :\n",
        "        input_shape=(224, 224, 3)\n",
        "        \n",
        "    # Creating a new model on top\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    \n",
        "    #  Float casting\n",
        "    x = tf.cast(inputs, tf.float32)\n",
        "\n",
        "    # Data Augmentation \n",
        "    x = data_augmentation(x)\n",
        "\n",
        "    # Default Preprocess Function for our Pre-trained Models\n",
        "    x = preprocess_func[pretrained_model_name](x)\n",
        "    \n",
        "    # Creating our base model\n",
        "    base_model = model(weights=\"imagenet\", \n",
        "                        include_top=False, \n",
        "                        input_shape=input_shape)\n",
        "    # Frezing the base_model weights\n",
        "    base_model.trainable = False\n",
        "     \n",
        "    # Building the model\n",
        "    x = base_model(x, training = False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    outputs = tf.keras.layers.Dense(102, activation='softmax')(x)\n",
        "    reg_model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    reg_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    history = reg_model.fit(train_ds, epochs = 20, validation_data=val_ds, callbacks=[es])\n",
        "    \n",
        "    # Adding model benchmarks to compare later\n",
        "    model_benchmarks['pretrained_model_name'].append(pretrained_model_name)\n",
        "    model_benchmarks['num_params'].append(base_model.count_params())\n",
        "    model_benchmarks['validation_accuracy'].append(history.history['val_accuracy'][-1])  \n",
        "    cnt = cnt+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_HvwXu5RJc1",
        "outputId": "736257e4-632d-4f84-bc43-27881bbda7b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/33 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "Epoch 1/20\n",
            "48/48 [==============================] - 23s 284ms/step - loss: 10.1865 - accuracy: 0.0260 - val_loss: 6.4855 - val_accuracy: 0.1155\n",
            "Epoch 2/20\n",
            "48/48 [==============================] - 11s 223ms/step - loss: 6.2390 - accuracy: 0.1315 - val_loss: 4.2173 - val_accuracy: 0.2720\n",
            "Epoch 3/20\n",
            "48/48 [==============================] - 11s 227ms/step - loss: 4.1038 - accuracy: 0.2643 - val_loss: 2.9089 - val_accuracy: 0.3875\n",
            "Epoch 4/20\n",
            "48/48 [==============================] - 11s 232ms/step - loss: 2.8748 - accuracy: 0.3783 - val_loss: 2.2813 - val_accuracy: 0.4971\n",
            "Epoch 5/20\n",
            "48/48 [==============================] - 11s 238ms/step - loss: 2.2354 - accuracy: 0.4733 - val_loss: 1.9543 - val_accuracy: 0.5499\n",
            "Epoch 6/20\n",
            "48/48 [==============================] - 11s 239ms/step - loss: 1.8430 - accuracy: 0.5423 - val_loss: 1.6793 - val_accuracy: 0.5871\n",
            "Epoch 7/20\n",
            "48/48 [==============================] - 11s 236ms/step - loss: 1.5981 - accuracy: 0.5846 - val_loss: 1.5214 - val_accuracy: 0.6419\n",
            "Epoch 8/20\n",
            "48/48 [==============================] - 11s 233ms/step - loss: 1.2997 - accuracy: 0.6413 - val_loss: 1.4122 - val_accuracy: 0.6477\n",
            "Epoch 9/20\n",
            "48/48 [==============================] - 11s 230ms/step - loss: 1.0842 - accuracy: 0.6973 - val_loss: 1.2926 - val_accuracy: 0.6849\n",
            "Epoch 10/20\n",
            "48/48 [==============================] - 11s 230ms/step - loss: 0.9291 - accuracy: 0.7305 - val_loss: 1.2324 - val_accuracy: 0.6986\n",
            "Epoch 11/20\n",
            "48/48 [==============================] - 11s 227ms/step - loss: 0.8335 - accuracy: 0.7676 - val_loss: 1.1693 - val_accuracy: 0.7202\n",
            "Epoch 12/20\n",
            "48/48 [==============================] - 11s 232ms/step - loss: 0.7690 - accuracy: 0.7826 - val_loss: 1.1374 - val_accuracy: 0.7025\n",
            "Epoch 13/20\n",
            "48/48 [==============================] - 11s 240ms/step - loss: 0.6756 - accuracy: 0.7949 - val_loss: 1.0639 - val_accuracy: 0.7515\n",
            "Epoch 14/20\n",
            "48/48 [==============================] - 11s 237ms/step - loss: 0.6079 - accuracy: 0.8112 - val_loss: 1.0214 - val_accuracy: 0.7554\n",
            "Epoch 15/20\n",
            "48/48 [==============================] - 11s 233ms/step - loss: 0.5515 - accuracy: 0.8307 - val_loss: 1.0314 - val_accuracy: 0.7534\n",
            "Epoch 16/20\n",
            "48/48 [==============================] - 11s 234ms/step - loss: 0.5343 - accuracy: 0.8509 - val_loss: 1.0165 - val_accuracy: 0.7534\n",
            "Epoch 17/20\n",
            "48/48 [==============================] - 11s 231ms/step - loss: 0.4700 - accuracy: 0.8691 - val_loss: 0.9985 - val_accuracy: 0.7476\n",
            "Epoch 18/20\n",
            "48/48 [==============================] - 11s 230ms/step - loss: 0.4269 - accuracy: 0.8665 - val_loss: 0.9728 - val_accuracy: 0.7652\n",
            "Epoch 19/20\n",
            "48/48 [==============================] - 11s 226ms/step - loss: 0.3942 - accuracy: 0.8848 - val_loss: 0.9769 - val_accuracy: 0.7515\n",
            "Epoch 20/20\n",
            "48/48 [==============================] - 11s 233ms/step - loss: 0.3956 - accuracy: 0.8854 - val_loss: 0.9397 - val_accuracy: 0.7691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1/33 [04:27<2:22:47, 267.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting model benchmarks to a DataFrame\n",
        "\n",
        "# (Since our colab notebook crashed in the middle we only have the results of the last iteration, the rest of the results are tabulated in the report)\n",
        "\n",
        "benchmark_df = pd.DataFrame(model_benchmarks)\n",
        "benchmark_df.sort_values('validation_accuracy', inplace=True, ascending=False)\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "WoqHKwInRJSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b272ad8e-ab86-466f-e77b-141f69390ea9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  pretrained_model_name  num_params  validation_accuracy\n",
              "0                 VGG16    14714688              0.76908"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84650514-b511-43ad-b07c-a852e411360c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pretrained_model_name</th>\n",
              "      <th>num_params</th>\n",
              "      <th>validation_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VGG16</td>\n",
              "      <td>14714688</td>\n",
              "      <td>0.76908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84650514-b511-43ad-b07c-a852e411360c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84650514-b511-43ad-b07c-a852e411360c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84650514-b511-43ad-b07c-a852e411360c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the benchmarks as a csv to be used for comparison later\n",
        "benchmark_df.to_csv(\"transfer_learning_model_results_low_samples.csv\")"
      ],
      "metadata": {
        "id": "gbF2Bi8sVxYN"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}